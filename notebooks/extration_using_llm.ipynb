{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24075ba5",
   "metadata": {},
   "source": [
    "### Information extraction from documents using LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4fcc74",
   "metadata": {},
   "source": [
    "### GroqLLM  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7618e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "\n",
    "os.environ['GROQ_API_KEY'] = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f25d983",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"llama-3.1-8b-instant\"\n",
    "llm = ChatGroq(model=model_name,\n",
    "               temperature=0,\n",
    "               verbose=True\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5ed8410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of India is New Delhi.\n"
     ]
    }
   ],
   "source": [
    "response = llm.invoke(\"What is the capital of india?\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7521654e",
   "metadata": {},
   "source": [
    "#### Extract text from documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5404cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "\n",
    "\n",
    "def text_extractore(file_path):\n",
    "    text = \"\"\n",
    "    with pdfplumber.open(file_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            text += page.extract_text() + \"\\n\"\n",
    "\n",
    "    return text\n",
    "\n",
    "file_path = r\"..\\documents\\bhargavDasRsm.pdf\"\n",
    "chunks = text_extractore(file_path=file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb2ebffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bhargav Das\n",
      "+91 9871079256 | erbhargavdas@gmail.com | linkedin.com/in/bhrgvbhrgv | github.com/bhrgvbhrgv\n",
      "Education\n",
      "Baderia Global Institute of Engineering & Management Jabalpur\n",
      "Bachelor of Technology in Computer Science July 2022 - July 2026\n",
      "Aditya Convent Senior Secondary School Jabalpur\n",
      "Class XII July 2021 - July 2022\n",
      "Experience\n",
      "Freelanced — Full-Stack Web Developer Aug 2024 - Sept 2024\n",
      "Creative Interior India\n",
      "• Tech Stack: React.js, Next.js, CSS, Firebase\n",
      "• Achieved 90+ Google Lighthouse scores in performance, accessibility, and SEO through optimized architecture and\n",
      "clean code.\n",
      "• Attracted 1,000+ unique visitors within the first 3 months of launch through SEO and social sharing.\n",
      "• Integrated Firebase for scalable backend services including real-time database and secure hosting, ensuring 99.9%\n",
      "uptime.\n",
      "• Live Link: https://creativeconstruction.in/\n",
      "Internship: Front-End Web Developer Mar 2023 - May 2023\n",
      "DAO Info-Tech\n",
      "• Contributed to the development and launch of 6+ business websites, increasing client visibility and engagement by\n",
      "up to 40%.\n",
      "• Gained hands-on experience with HTML, CSS, JavaScript, and modern frameworks (e.g., React.js), reducing\n",
      "development time by 25% through reusable components.\n",
      "• Assisted in debugging and performance optimization, leading to 30% faster page load speeds and improved user\n",
      "retention.\n",
      "• Ensured mobile responsiveness across 20+ device breakpoints, improving cross-platform accessibility scores by 15%.\n",
      "Projects\n",
      "StreamTweet | React, Axios, Express, Mongoose, Multer, JWT and Bycrpt May 2025 – May 2025\n",
      "• Developed a full-stack web application that integrates core functionalities of YouTube and Twitter using React.js,\n",
      "Node.js, Express, and MongoDB.\n",
      "• Designed and implemented video upload, streaming, commenting, and like features to simulate YouTube’s user\n",
      "experience.\n",
      "• Built Twitter-style post creation, feed rendering, and user interaction modules including retweets, likes, share and\n",
      "replies.\n",
      "• Managed user authentication, session handling, and role-based access control with JWT and bcrypt for secure login\n",
      "and operations.\n",
      "LiveConnect | React, Axios, Socket.io, Express, Mongoose June 2025 – June 2025\n",
      "• Built a real-time chat application using the MERN stack and Socket.io for bidirectional communication.\n",
      "• Designedandimplementedover10RESTfulAPIroutesformessagehandling, usermanagement, andchatrooms.\n",
      "• Developed the frontend using React.js and integrated multiple third-party libraries including Axios and React\n",
      "Router.\n",
      "• Used MongoDB to store user profiles and chat logs with efficient schema design and querying.\n",
      "Technical Skills\n",
      "Languages: JavaScript, HTML/CSS, C++, SQL, Python\n",
      "Frameworks: React.js, Node.js, Express.js, Tailwind CSS\n",
      "Libraries: MongoDB, THREE.js\n",
      "Developer Tools: Git, RESTful APIs, User Testing Tools\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5132bdbe",
   "metadata": {},
   "source": [
    "#### Extract skills from resume and JD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "e81eabd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "prompt_template = PromptTemplate.from_template(\"\"\"\n",
    "You are an expert HR assistant that extracts technical and professional skills from resumes and job descriptions.\n",
    "\n",
    "Instructions:\n",
    "- Extract only SKILLS from the given text.\n",
    "- Normalize variations into a common standard (e.g., VLOOKUP → Excel, Random Forest → Machine Learning).\n",
    "- Return output strictly in JSON format like:\n",
    "{{\"Skill1\", \"Skill2\", \"Skill3\"}}\n",
    "- Don't return any additional text or explanations.\n",
    "\n",
    "Text:\n",
    "{context}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "7815edf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nYou are an expert HR assistant that extracts technical and professional skills from resumes and job descriptions.\\n\\nInstructions:\\n- Extract only SKILLS from the given text.\\n- Normalize variations into a common standard (e.g., VLOOKUP → Excel, Random Forest → Machine Learning).\\n- Return output strictly in JSON format like:\\n{\"Skill1\", \"Skill2\", \"Skill3\"}\\n- Don\\'t return any additional text or explanations.\\n\\nText:\\nKamal\\n'"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template.format(context=\"Kamal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "a0c26a8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'```json\\n{\\n  \"JavaScript\", \\n  \"HTML/CSS\", \\n  \"C++\", \\n  \"SQL\", \\n  \"Python\", \\n  \"React.js\", \\n  \"Node.js\", \\n  \"Express.js\", \\n  \"Tailwind CSS\", \\n  \"MongoDB\", \\n  \"THREE.js\", \\n  \"Git\", \\n  \"RESTful APIs\", \\n  \"User Testing Tools\", \\n  \"Firebase\", \\n  \"CSS\", \\n  \"Next.js\", \\n  \"Axios\", \\n  \"Mongoose\", \\n  \"Multer\", \\n  \"JWT\", \\n  \"Bycrpt\", \\n  \"Socket.io\", \\n  \"React Router\"\\n}\\n```'"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = llm.invoke(input=prompt_template.format(context=chunks))\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef970861",
   "metadata": {},
   "source": [
    "#### --- Step 2: Extract Skills (LLM can be used, here simple mock) ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f26987",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "import json\n",
    "\n",
    "def extract_skill_from_documents(chunk: str):\n",
    "\n",
    "    \"\"\"Chunk is text from documents\"\"\"\n",
    "    prompt_template = PromptTemplate.from_template(\"\"\"\n",
    "    You are an expert HR assistant that extracts technical and professional skills from resumes and job descriptions.\n",
    "\n",
    "    Instructions:\n",
    "    - Extract only SKILLS from the given text.\n",
    "    - Normalize variations into a common standard (e.g., VLOOKUP → Excel, Random Forest → Machine Learning).\n",
    "    - Return output strictly in JSON format like:\n",
    "    {{\"Skill1\", \"Skill2\", \"Skill3\"}}\n",
    "    - Don't return any additional text or explanations.\n",
    "\n",
    "    Text:\n",
    "    {context}\n",
    "    \"\"\")\n",
    "\n",
    "    prompt = prompt_template.format(context=chunk)\n",
    "    response = llm.invoke(input=prompt)\n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8a766b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_set_of_skills(llm_response: str):\n",
    "    import re\n",
    "    \"\"\"Convert LLM response to a set of skills\"\"\"\n",
    "    resume_skills = re.findall(r'\"([^\"]+)\"', llm_response)\n",
    "    # Convert to set\n",
    "    resume_kills_set = set(resume_skills)\n",
    "\n",
    "    return resume_kills_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6f81ca10",
   "metadata": {},
   "outputs": [],
   "source": [
    "skills = extract_skill_from_documents(chunk=chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0bce9f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_skills_set = get_set_of_skills(llm_response=skills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5d99cf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_description = \"\"\"\n",
    "Job Description:\n",
    "We are seeking a Data Analyst to join our analytics team. The candidate will be responsible for collecting, cleaning, analyzing, and interpreting large datasets to provide insights that support business decision-making.\n",
    "Key Responsibilities:\n",
    "Collect, process, and analyze structured and unstructured data.\n",
    "Build dashboards and reports using Power BI or Tableau.\n",
    "Write SQL queries to extract data from relational databases.\n",
    "Apply statistical methods to identify trends and patterns.\n",
    "Work with cross-functional teams to provide actionable insights.\n",
    "Present findings in a clear and concise manner to stakeholders.\n",
    "Required Skills & Qualifications:\n",
    "Bachelor’s degree in Statistics, Mathematics, Computer Science, Economics, or related field.\n",
    "Strong knowledge of SQL, Python, Excel.\n",
    "Hands-on experience with Power BI / Tableau.\n",
    "Knowledge of statistical analysis, regression, hypothesis testing.\n",
    "Strong communication and problem-solving skills.\n",
    "Preferred Skills:\n",
    "Experience with Big Data tools (Spark, Hadoop).\n",
    "Familiarity with machine learning basics.\n",
    "Exposure to cloud platforms (AWS, GCP, Azure).\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "64fd9990",
   "metadata": {},
   "outputs": [],
   "source": [
    "jd_skills = extract_skill_from_documents(chunk=job_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c8952e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "jd_skills_set = get_set_of_skills(llm_response=jd_skills)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13516837",
   "metadata": {},
   "source": [
    "#### --- Step 3: Skill Match Score ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "68a55d8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Python', 'SQL'}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_skills = resume_skills_set.intersection(jd_skills_set)\n",
    "common_skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "402a9553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching skills score with Resume and JD: 10.53 %\n"
     ]
    }
   ],
   "source": [
    "skill_score = len(common_skills) / len(jd_skills_set) * 100\n",
    "print(F\"Matching skills score with Resume and JD: {skill_score:.2f} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae0af3b",
   "metadata": {},
   "source": [
    "#### # --- Step 4: Semantic Similarity (JD vs Resume) ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e8154fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\Desktop\\all repo\\Resume-parser-LLM\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3861eb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer(model_name_or_path=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "20bf874c",
   "metadata": {},
   "outputs": [],
   "source": [
    "jd_embedding = model.encode(job_description, convert_to_tensor=True)\n",
    "resume_embedding = model.encode(chunks, convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a156c4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic_score = float(util.cos_sim(jd_embedding, resume_embedding)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "534de876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching skills score with Resume and JD: 42.50 %\n"
     ]
    }
   ],
   "source": [
    "print(F\"Matching skills score with Resume and JD: {semantic_score:.2f} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452ce71c",
   "metadata": {},
   "source": [
    "#### --- Step 5: Final Weighted Score ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b9c2e244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score for matching skills with Resume and JD: 20.12 %\n"
     ]
    }
   ],
   "source": [
    "final_weighted_score = 0.7 * skill_score + 0.3 * semantic_score\n",
    "print(F\"Final score for matching skills with Resume and JD: {final_weighted_score:.2f} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "35b1a26d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skill Score: 10.53 %\n",
      "Semantic Score: 42.5 %\n",
      "Final Match Score: 20.12 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Skill Score:\", round(skill_score,2), \"%\")\n",
    "print(\"Semantic Score:\", round(semantic_score,2), \"%\")\n",
    "print(\"Final Match Score:\", round(final_weighted_score,2), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82decb3",
   "metadata": {},
   "source": [
    "## Cosine similarity testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "fefbc0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \"king\"\n",
    "text2 = \"queen\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "1709e89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text1_encode = model.encode(text1, return_tensors=\"pt\")\n",
    "text2_encode = model.encode(text2, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "ef2f5ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic_score = float(util.cos_sim(text1_encode, text2_encode)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "ea9a1c8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68.07126998901367"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "semantic_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "4a6cd827",
   "metadata": {},
   "outputs": [],
   "source": [
    "jd = \"\"\"\n",
    "Job Title: Machine Learning Engineer\n",
    "Experience Required: 2+ years\n",
    "Location: Bangalore, India\n",
    "Job Type: Full-time\n",
    "\n",
    "Responsibilities:\n",
    "\n",
    "Design, build, and deploy machine learning models for predictive analytics.\n",
    "\n",
    "Preprocess and analyze structured and unstructured data.\n",
    "\n",
    "Implement feature engineering, model training, and hyperparameter tuning.\n",
    "\n",
    "Work with Python libraries (Pandas, NumPy, Scikit-learn, TensorFlow/PyTorch).\n",
    "\n",
    "Collaborate with data engineers and software developers to integrate models into production systems.\n",
    "\n",
    "Monitor model performance and retrain as needed.\n",
    "\n",
    "Requirements:\n",
    "\n",
    "Bachelor’s degree in Computer Science, Data Science, or related field.\n",
    "\n",
    "Strong knowledge of supervised and unsupervised ML algorithms (Linear Regression, Random Forest, SVM, Clustering).\n",
    "\n",
    "Hands-on experience with Python and ML libraries.\n",
    "\n",
    "Exposure to deep learning frameworks (TensorFlow, PyTorch).\n",
    "\n",
    "Familiarity with SQL and cloud platforms (AWS/GCP/Azure).\n",
    "\n",
    "Excellent problem-solving and analytical skills.\n",
    "\n",
    "Nice to Have:\n",
    "\n",
    "Experience with NLP or Computer Vision projects.\n",
    "\n",
    "Knowledge of MLOps practices (Docker, MLflow, CI/CD).\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "880d1bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume = \"\"\"\n",
    "Name: Rahul Sharma\n",
    "Email: rahul.sharma@gmail.com\n",
    "\n",
    "Phone: +91-9876543210\n",
    "\n",
    "Summary:\n",
    "Machine Learning Engineer with 3 years of experience in developing, deploying, and optimizing machine learning models. Skilled in Python, Scikit-learn, TensorFlow, and cloud-based ML deployment. Experienced in working with structured/unstructured data and delivering data-driven solutions for business problems.\n",
    "\n",
    "Technical Skills:\n",
    "\n",
    "Programming: Python, SQL, R\n",
    "\n",
    "ML/DL Frameworks: Scikit-learn, TensorFlow, PyTorch\n",
    "\n",
    "Data Tools: Pandas, NumPy, Matplotlib, Seaborn\n",
    "\n",
    "Databases: MySQL, MongoDB\n",
    "\n",
    "Cloud Platforms: AWS (S3, SageMaker), GCP AI Platform\n",
    "\n",
    "Other Tools: Git, Docker, MLflow\n",
    "\n",
    "Work Experience:\n",
    "Machine Learning Engineer | ABC Tech Solutions | Bangalore | Jul 2022 – Present\n",
    "\n",
    "Built and deployed predictive ML models for customer churn, improving retention rate by 12%.\n",
    "\n",
    "Developed recommendation engine using collaborative filtering and deep learning techniques.\n",
    "\n",
    "Automated feature engineering pipelines, reducing preprocessing time by 40%.\n",
    "\n",
    "Deployed models on AWS SageMaker with Dockerized microservices.\n",
    "\n",
    "Collaborated with data engineers to handle 1TB+ datasets efficiently.\n",
    "\n",
    "Data Analyst (ML Focus) | XYZ Analytics | Pune | Jul 2021 – Jun 2022\n",
    "\n",
    "Designed regression and classification models for financial forecasting.\n",
    "\n",
    "Implemented clustering models for customer segmentation.\n",
    "\n",
    "Conducted feature engineering and data cleaning using Python and SQL.\n",
    "\n",
    "Visualized insights with Matplotlib, Seaborn, and Power BI.\n",
    "\n",
    "Education:\n",
    "B.Tech in Computer Science, Pune University (2017 – 2021)\n",
    "\n",
    "✅ This way, you now have:\n",
    "\n",
    "JD → defines what the company is looking for.\n",
    "\n",
    "Resume → defines the candidate’s experience, slightly more than required.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "2c7d2dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "4e737905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Step 1: Embedding Model ----------\n",
    "embed_model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "065e3cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Step 2: Prompt for Skill Extraction ----------\n",
    "skill_prompt = PromptTemplate.from_template(\"\"\"\n",
    "    You are an expert HR assistant that extracts technical and professional skills from resumes and job descriptions.\n",
    "\n",
    "    Instructions:\n",
    "    - Extract only SKILLS from the given text.\n",
    "    - Normalize variations into a common standard (e.g., VLOOKUP → Excel, Random Forest → Machine Learning).\n",
    "    - Return output strictly in JSON format like:\n",
    "    {{\"Skill1\", \"Skill2\", \"Skill3\"}}\n",
    "    - Don't return any additional text or explanations.\n",
    "\n",
    "    Text:\n",
    "    {context}\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d3ea9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import ast\n",
    "\n",
    "\n",
    "def extract_skills(text: str):\n",
    "\n",
    "    # ---------- Step 2: Prompt for Skill Extraction ----------\n",
    "    skill_prompt = PromptTemplate.from_template(\"\"\"\n",
    "            You are an expert HR assistant that extracts technical and professional skills from resumes and job descriptions.\n",
    "\n",
    "            Instructions:\n",
    "            - Extract only SKILLS from the given text.\n",
    "            - Normalize variations into a common standard (e.g., VLOOKUP → Excel, Random Forest → Machine Learning).\n",
    "            - Return output strictly in JSON format like:\n",
    "            {{\"Skill1\", \"Skill2\", \"Skill3\"}}\n",
    "            - Don't return any additional text or explanations.\n",
    "\n",
    "            Text:\n",
    "            {context}\n",
    "            \"\"\")\n",
    "\n",
    "    prompt = skill_prompt.format(context=text)\n",
    "    response = llm.invoke(prompt)\n",
    "    jd_skills = response.content.strip()\n",
    "    \n",
    "    match = re.search(r\"\\{.*\\}\", jd_skills, re.DOTALL)\n",
    "    if match:\n",
    "        raw = match.group(0)\n",
    "\n",
    "    jd_skills = ast.literal_eval(raw)\n",
    "    return jd_skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "5b06bc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "jd_skills_set = extract_skills(text=jd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "c447d126",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_skills_set = extract_skills(text=resume)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c31eaec",
   "metadata": {},
   "source": [
    "## Score using intersation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "3937f777",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AWS',\n",
       " 'Clustering',\n",
       " 'Docker',\n",
       " 'GCP',\n",
       " 'MLflow',\n",
       " 'Machine Learning',\n",
       " 'NumPy',\n",
       " 'Pandas',\n",
       " 'PyTorch',\n",
       " 'Python',\n",
       " 'SQL',\n",
       " 'Scikit-learn',\n",
       " 'TensorFlow'}"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_skills = resume_skills_set.intersection(jd_skills_set)\n",
    "common_skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "d1896879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching skills score with Resume and JD: 61.90 %\n"
     ]
    }
   ],
   "source": [
    "skill_score = len(common_skills) / len(jd_skills_set) * 100\n",
    "print(F\"Matching skills score with Resume and JD: {skill_score:.2f} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b069b2",
   "metadata": {},
   "source": [
    "## Similarity score using LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "3549c75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_skills(text: str):\n",
    "    import re\n",
    "    import ast\n",
    "    prompt = skill_prompt.format(context=text)\n",
    "    response = llm.invoke(prompt)\n",
    "    jd_skills = response.content.strip()\n",
    "    \n",
    "    match = re.search(r\"\\{.*\\}\", jd_skills, re.DOTALL)\n",
    "    if match:\n",
    "        raw = match.group(0)\n",
    "\n",
    "    return raw\n",
    "\n",
    "\n",
    "jd_skills_set = extract_skills(text=jd)\n",
    "resume_skills = extract_skills(text=resume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "f2d9f787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Step 3: Compute Similarity ----------\n",
    "def compute_match_score(jd_skills, resume_skills):\n",
    "    # Convert skills into embeddings\n",
    "    jd_embeddings = embed_model.encode(jd_skills, convert_to_tensor=True)\n",
    "    resume_embeddings = embed_model.encode(resume_skills, convert_to_tensor=True)\n",
    "\n",
    "    # Compute pairwise similarity\n",
    "    cosine_scores = util.cos_sim(jd_embeddings, resume_embeddings)\n",
    "\n",
    "    # Final percentage\n",
    "    return round(cosine_scores.mean().item() * 100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "e09f942f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91.52"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_match_score(jd_skills=jd_skills_set, resume_skills=resume_skills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "87b2f0af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Resume Match Score: 91.52%\n"
     ]
    }
   ],
   "source": [
    "# ---------- Step 4: Run Pipeline ---------\n",
    "\n",
    "score = compute_match_score(jd_skills=jd_skills_set, resume_skills=resume_skills)\n",
    "print(f\"✅ Resume Match Score: {score}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a503fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bfc728",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05941169",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
